# ðŸŽ“ Classical Machine Learning â€“ Gold Standard Interview Problems

A curated set of classical ML problem types and benchmarks commonly discussed in interviews and academic learning. Great for grounding your ML knowledge before deep learning.

| **Category**                       | **Example / Benchmark**                                                                  |
| ---------------------------------- | ---------------------------------------------------------------------------------------- |
| **[[Binary Classification]]**      | Spam vs Ham (SMS Spam Collection), Breast Cancer (UCI), Titanic survival prediction      |
| **[[Multiclass Classification]]**  | MNIST digit classification, Iris dataset, Fashion-MNIST                                  |
| **[[Regression]]**                 | Boston Housing, California Housing, Bike Sharing Dataset                                 |
| **[[Ordinal Regression]]**         | Predicting ratings (1â€“5 stars), income level prediction from census data                 |
| **[[Multi-label Classification]]** | Movie genre prediction (IMDb), tagging StackOverflow questions                           |
| **[[Time Series Forecasting]]**    | Stock price prediction, energy consumption (Household Power Consumption dataset)         |
| **[[Outlier/Anomaly Detection]]**  | Credit card fraud (Kaggle), Network intrusion (NSL-KDD)                                  |
| **[[Clustering]]**                 | Customer segmentation (Mall Customers), image color quantization with K-Means            |
| **[[Dimensionality Reduction]]**   | PCA on facial images (Eigenfaces), t-SNE/UMAP on text embeddings                         |
| **[[Recommendation Systems]]**     | MovieLens collaborative filtering, Book-Crossing dataset                                 |
| **[[Survival Analysis]]**          | Patient prognosis prediction, reliability modeling (using Kaplan-Meier / Cox models)     |
| **[[Ensemble Learning]]**          | Random Forests or Gradient Boosting on tabular datasets (e.g., Adult, Titanic)           |
| **[[Feature Selection]]**          | Lasso regression on gene expression, Recursive Feature Elimination (RFE) on tabular data |
| **[[Model Calibration]]**          | Reliability curves on classifiers trained on CIFAR-10 or tabular datasets                |
| **[[Imbalanced Classification]]**  | Credit fraud, rare disease detection (use SMOTE, focal loss, class weights)              |
